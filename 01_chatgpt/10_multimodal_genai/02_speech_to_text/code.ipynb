{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Introduction\n",
    "\n",
    "The Audio API provides two speech to text endpoints, transcriptions and translations, based on our state-of-the-art open source large-v2 Whisper model. They can be used to:\n",
    "\n",
    "Transcribe audio into whatever language the audio is in.\n",
    "\n",
    "    Translate and transcribe the audio into english.\n",
    "    File uploads are currently limited to 25 MB and the following input file types are supported: mp3, mp4, mpeg, mpga, m4a, wav, and webm.\n",
    "\n",
    "Transcriptions\n",
    "\n",
    "The transcriptions API takes as input the audio file you want to transcribe and the desired output file format for the transcription of the audio. We currently support multiple input and output file formats.\n",
    "\n",
    "By default, the response type will be json with the raw text included.\n",
    "\n",
    "{\n",
    "  \"text\": \"Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger.\n",
    "....\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Invalid file format. Supported formats: ['flac', 'm4a', 'mp3', 'mp4', 'mpeg', 'mpga', 'oga', 'ogg', 'wav', 'webm']\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m client \u001b[39m=\u001b[39m OpenAI()\n\u001b[1;32m      4\u001b[0m audio_file \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39murdu.mp3\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m transcript \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39maudio\u001b[39m.\u001b[39mtranscriptions\u001b[39m.\u001b[39mcreate(\n\u001b[1;32m      6\u001b[0m   model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwhisper-1\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m      7\u001b[0m   file\u001b[39m=\u001b[39maudio_file, \n\u001b[1;32m      8\u001b[0m   response_format\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/resources/audio/transcriptions.py:99\u001b[0m, in \u001b[0;36mTranscriptions.create\u001b[0;34m(self, file, model, language, prompt, response_format, temperature, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mif\u001b[39;00m files:\n\u001b[1;32m     94\u001b[0m     \u001b[39m# It should be noted that the actual Content-Type header that will be\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[39m# sent to the server will contain a `boundary` parameter, e.g.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[39m# multipart/form-data; boundary=---abc--\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     extra_headers \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mmultipart/form-data\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(extra_headers \u001b[39mor\u001b[39;00m {})}\n\u001b[0;32m---> 99\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post(\n\u001b[1;32m    100\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m/audio/transcriptions\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    101\u001b[0m     body\u001b[39m=\u001b[39mmaybe_transform(body, transcription_create_params\u001b[39m.\u001b[39mTranscriptionCreateParams),\n\u001b[1;32m    102\u001b[0m     files\u001b[39m=\u001b[39mfiles,\n\u001b[1;32m    103\u001b[0m     options\u001b[39m=\u001b[39mmake_request_options(\n\u001b[1;32m    104\u001b[0m         extra_headers\u001b[39m=\u001b[39mextra_headers, extra_query\u001b[39m=\u001b[39mextra_query, extra_body\u001b[39m=\u001b[39mextra_body, timeout\u001b[39m=\u001b[39mtimeout\n\u001b[1;32m    105\u001b[0m     ),\n\u001b[1;32m    106\u001b[0m     cast_to\u001b[39m=\u001b[39mTranscription,\n\u001b[1;32m    107\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:1063\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[1;32m   1050\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1051\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1059\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m   1060\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[1;32m   1061\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[1;32m   1062\u001b[0m     )\n\u001b[0;32m-> 1063\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest(cast_to, opts, stream\u001b[39m=\u001b[39mstream, stream_cls\u001b[39m=\u001b[39mstream_cls))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:842\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    834\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    835\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    840\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    841\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m--> 842\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request(\n\u001b[1;32m    843\u001b[0m         cast_to\u001b[39m=\u001b[39mcast_to,\n\u001b[1;32m    844\u001b[0m         options\u001b[39m=\u001b[39moptions,\n\u001b[1;32m    845\u001b[0m         stream\u001b[39m=\u001b[39mstream,\n\u001b[1;32m    846\u001b[0m         stream_cls\u001b[39m=\u001b[39mstream_cls,\n\u001b[1;32m    847\u001b[0m         remaining_retries\u001b[39m=\u001b[39mremaining_retries,\n\u001b[1;32m    848\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:885\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    883\u001b[0m     \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    884\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n\u001b[0;32m--> 885\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_status_error_from_response(err\u001b[39m.\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mTimeoutException \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    887\u001b[0m     \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"Invalid file format. Supported formats: ['flac', 'm4a', 'mp3', 'mp4', 'mpeg', 'mpga', 'oga', 'ogg', 'wav', 'webm']\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "audio_file = open(\"urdu.mp3\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\", \n",
    "  file=audio_file, \n",
    "  response_format=\"text\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transcript' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m transcript\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transcript' is not defined"
     ]
    }
   ],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Invalid file format. Supported formats: ['flac', 'm4a', 'mp3', 'mp4', 'mpeg', 'mpga', 'oga', 'ogg', 'wav', 'webm']\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m client \u001b[39m=\u001b[39m OpenAI()\n\u001b[1;32m      4\u001b[0m audio_file\u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39murdu.mp3\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m transcript \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39maudio\u001b[39m.\u001b[39mtranslations\u001b[39m.\u001b[39mcreate(\n\u001b[1;32m      6\u001b[0m   model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwhisper-1\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m      7\u001b[0m   file\u001b[39m=\u001b[39maudio_file\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m transcript\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/resources/audio/translations.py:92\u001b[0m, in \u001b[0;36mTranslations.create\u001b[0;34m(self, file, model, prompt, response_format, temperature, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39mif\u001b[39;00m files:\n\u001b[1;32m     87\u001b[0m     \u001b[39m# It should be noted that the actual Content-Type header that will be\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     \u001b[39m# sent to the server will contain a `boundary` parameter, e.g.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     \u001b[39m# multipart/form-data; boundary=---abc--\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     extra_headers \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mmultipart/form-data\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(extra_headers \u001b[39mor\u001b[39;00m {})}\n\u001b[0;32m---> 92\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post(\n\u001b[1;32m     93\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m/audio/translations\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     94\u001b[0m     body\u001b[39m=\u001b[39mmaybe_transform(body, translation_create_params\u001b[39m.\u001b[39mTranslationCreateParams),\n\u001b[1;32m     95\u001b[0m     files\u001b[39m=\u001b[39mfiles,\n\u001b[1;32m     96\u001b[0m     options\u001b[39m=\u001b[39mmake_request_options(\n\u001b[1;32m     97\u001b[0m         extra_headers\u001b[39m=\u001b[39mextra_headers, extra_query\u001b[39m=\u001b[39mextra_query, extra_body\u001b[39m=\u001b[39mextra_body, timeout\u001b[39m=\u001b[39mtimeout\n\u001b[1;32m     98\u001b[0m     ),\n\u001b[1;32m     99\u001b[0m     cast_to\u001b[39m=\u001b[39mTranslation,\n\u001b[1;32m    100\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:1063\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[1;32m   1050\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1051\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1059\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m   1060\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[1;32m   1061\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[1;32m   1062\u001b[0m     )\n\u001b[0;32m-> 1063\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest(cast_to, opts, stream\u001b[39m=\u001b[39mstream, stream_cls\u001b[39m=\u001b[39mstream_cls))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:842\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    834\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    835\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    840\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    841\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m--> 842\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request(\n\u001b[1;32m    843\u001b[0m         cast_to\u001b[39m=\u001b[39mcast_to,\n\u001b[1;32m    844\u001b[0m         options\u001b[39m=\u001b[39moptions,\n\u001b[1;32m    845\u001b[0m         stream\u001b[39m=\u001b[39mstream,\n\u001b[1;32m    846\u001b[0m         stream_cls\u001b[39m=\u001b[39mstream_cls,\n\u001b[1;32m    847\u001b[0m         remaining_retries\u001b[39m=\u001b[39mremaining_retries,\n\u001b[1;32m    848\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:885\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    883\u001b[0m     \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    884\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n\u001b[0;32m--> 885\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_status_error_from_response(err\u001b[39m.\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mTimeoutException \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    887\u001b[0m     \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"Invalid file format. Supported formats: ['flac', 'm4a', 'mp3', 'mp4', 'mpeg', 'mpga', 'oga', 'ogg', 'wav', 'webm']\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "audio_file= open(\"urdu.mp3\", \"rb\")\n",
    "transcript = client.audio.translations.create(\n",
    "  model=\"whisper-1\", \n",
    "  file=audio_file\n",
    ")\n",
    "\n",
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting ffprobe\n",
      "  Downloading ffprobe-0.5.zip (3.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: ffprobe\n",
      "  Building wheel for ffprobe (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffprobe: filename=ffprobe-0.5-py3-none-any.whl size=3406 sha256=059bd6d4cad20b5c78e93e0510cd43e7d5bd2f96d3a4b130548d5fdc5915edb6\n",
      "  Stored in directory: /home/maya/.cache/pip/wheels/2c/cb/c1/10daee0c3fad04c9d900006cd0f24bdd47afb74a5c1c085795\n",
      "Successfully built ffprobe\n",
      "Installing collected packages: pydub, ffprobe\n",
      "Successfully installed ffprobe-0.5 pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub ffprobe --upgrade --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: brew\n",
      "ffprobe version 6.0-6 Copyright (c) 2007-2023 the FFmpeg developers\n",
      "built with gcc 13 (Debian 13.2.0-2)\n",
      "configuration: --prefix=/usr --extra-version=6 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libglslang --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librist --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --disable-sndio --enable-libjxl --enable-pocketsphinx --enable-librsvg --enable-libvpl --disable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-libplacebo --enable-librav1e --enable-shared\n",
      "libavutil      58.  2.100 / 58.  2.100\n",
      "libavcodec     60.  3.100 / 60.  3.100\n",
      "libavformat    60.  3.100 / 60.  3.100\n",
      "libavdevice    60.  1.100 / 60.  1.100\n",
      "libavfilter     9.  3.100 /  9.  3.100\n",
      "libswscale      7.  1.100 /  7.  1.100\n",
      "libswresample   4. 10.100 /  4. 10.100\n",
      "libpostproc    57.  1.100 / 57.  1.100\n"
     ]
    }
   ],
   "source": [
    "!brew install ffmpeg\n",
    "!ffprobe -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/m.qasim/Desktop/PIAIC/learn-generative-ai/16_multimodal_genai/02 Speech to text/urdu.mp3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydub\u001b[39;00m \u001b[39mimport\u001b[39;00m AudioSegment\n\u001b[0;32m----> 3\u001b[0m song \u001b[39m=\u001b[39m AudioSegment\u001b[39m.\u001b[39mfrom_mp3(\u001b[39m\"\u001b[39m\u001b[39m/Users/m.qasim/Desktop/PIAIC/learn-generative-ai/16_multimodal_genai/02 Speech to text/urdu.mp3\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[39m# PyDub handles time in milliseconds\u001b[39;00m\n\u001b[1;32m      6\u001b[0m ten_minutes \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m \u001b[39m*\u001b[39m \u001b[39m60\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pydub/audio_segment.py:796\u001b[0m, in \u001b[0;36mAudioSegment.from_mp3\u001b[0;34m(cls, file, parameters)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_mp3\u001b[39m(\u001b[39mcls\u001b[39m, file, parameters\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 796\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mfrom_file(file, \u001b[39m'\u001b[39m\u001b[39mmp3\u001b[39m\u001b[39m'\u001b[39m, parameters\u001b[39m=\u001b[39mparameters)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pydub/audio_segment.py:651\u001b[0m, in \u001b[0;36mAudioSegment.from_file\u001b[0;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     filename \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 651\u001b[0m file, close_file \u001b[39m=\u001b[39m _fd_or_path_or_tempfile(file, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m, tempfile\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    653\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mformat\u001b[39m:\n\u001b[1;32m    654\u001b[0m     \u001b[39mformat\u001b[39m \u001b[39m=\u001b[39m \u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mlower()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pydub/utils.py:60\u001b[0m, in \u001b[0;36m_fd_or_path_or_tempfile\u001b[0;34m(fd, mode, tempfile)\u001b[0m\n\u001b[1;32m     57\u001b[0m     close_fd \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fd, basestring):\n\u001b[0;32m---> 60\u001b[0m     fd \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(fd, mode\u001b[39m=\u001b[39mmode)\n\u001b[1;32m     61\u001b[0m     close_fd \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/m.qasim/Desktop/PIAIC/learn-generative-ai/16_multimodal_genai/02 Speech to text/urdu.mp3'"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "song = AudioSegment.from_mp3(\"/Users/m.qasim/Desktop/PIAIC/learn-generative-ai/16_multimodal_genai/02 Speech to text/urdu.mp3\")\n",
    "\n",
    "# PyDub handles time in milliseconds\n",
    "ten_minutes = 10 * 60 * 1000\n",
    "\n",
    "first_10_minutes = song[:ten_minutes]\n",
    "\n",
    "first_10_minutes.export(\"chuck_10_25mb.mp3\", format=\"mp3\")\n",
    "first_10_minutes\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ : bool = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stateful, remember every conversation and keep \n",
    "\n",
    "## 1-assistant\n",
    "## 2-code interpreter\n",
    "## 2-retrieval\n",
    "\n",
    "## Select assistance data analysis , backhand working , 1-chatGPT version, which version use of LLM, \n",
    "## 2- Thread = q1, q2 conversation \n",
    "## 3- Run =  assistant + Thead , every thread, including text, LLM perform \n",
    "\n",
    "\n",
    "## poling\n",
    "## intrupt\n",
    "\n",
    "## asst.name \n",
    "## select pick model version\n",
    "## type instruction\n",
    "## tools\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client : OpenAI = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def getCurrentWeather(location:str, unit:str=\"fahrenheit\")->str | dict | None:\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"})\n",
    "    elif \"los angeles\" in location.lower():\n",
    "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"})\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n",
    "    \n",
    "\n",
    "def getNickname(location:str)->str:\n",
    "    \"\"\"Get the nickname of a city\"\"\"\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return \"tk\"\n",
    "    elif \"los angeles\" in location.lower():\n",
    "        return \"la\"\n",
    "    elif \"paris\" in location.lower():\n",
    "        return \"py\"\n",
    "    else:\n",
    "        return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def show_json(message, obj):\n",
    "    display(message, json.loads(obj.model_dump_json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.beta import Assistant\n",
    "\n",
    "assistant: Assistant = client.beta.assistants.create(\n",
    "  instructions=\"You are a weather bot. Use the provided functions to answer questions.\",\n",
    "  model=\"gpt-3.5-turbo-1106\",\n",
    "  tools=[{\n",
    "      \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"getCurrentWeather\",\n",
    "      \"description\": \"Get the weather in location\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\"type\": \"string\", \"description\": \"The city and state e.g. San Francisco, CA\"},\n",
    "          \"unit\": {\"type\": \"string\", \"enum\": [\"c\", \"f\"]}\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "      }\n",
    "    }\n",
    "  }, {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"getNickname\",\n",
    "      \"description\": \"Get the nickname of a city\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\"type\": \"string\", \"description\": \"The city and state e.g. San Francisco, CA\"},\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "      }\n",
    "    } \n",
    "  }]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_fzNe9S3rWyE6VCFpT8kclKXJ', created_at=1701114785, metadata={}, object='thread')\n"
     ]
    }
   ],
   "source": [
    "from openai.types.beta.thread import Thread\n",
    "\n",
    "thread: Thread  = client.beta.threads.create()\n",
    "\n",
    "print(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.beta.threads.thread_message import ThreadMessage\n",
    "\n",
    "# First Request\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"How is the weather in Los Angles?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_rrYcLrmC1vEvSdpfBoAzHEAv',\n",
       " 'assistant_id': None,\n",
       " 'content': [MessageContentText(text=Text(annotations=[], value='How is the weather in Los Angles?'), type='text')],\n",
       " 'created_at': 1701114806,\n",
       " 'file_ids': [],\n",
       " 'metadata': {},\n",
       " 'object': 'thread.message',\n",
       " 'role': 'user',\n",
       " 'run_id': None,\n",
       " 'thread_id': 'thread_fzNe9S3rWyE6VCFpT8kclKXJ'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.beta.threads.run import Run\n",
    "\n",
    "run: Run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'run_Rrj92XIk5FH2NHsEkwXkdt3q',\n",
       " 'assistant_id': 'asst_ZKSaQpVCBcGGrB67lgJ3guJl',\n",
       " 'cancelled_at': None,\n",
       " 'completed_at': None,\n",
       " 'created_at': 1701114848,\n",
       " 'expires_at': 1701115448,\n",
       " 'failed_at': None,\n",
       " 'file_ids': [],\n",
       " 'instructions': 'You are a weather bot. Use the provided functions to answer questions.',\n",
       " 'last_error': None,\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-3.5-turbo-1106',\n",
       " 'object': 'thread.run',\n",
       " 'required_action': None,\n",
       " 'started_at': None,\n",
       " 'status': 'queued',\n",
       " 'thread_id': 'thread_fzNe9S3rWyE6VCFpT8kclKXJ',\n",
       " 'tools': [ToolAssistantToolsFunction(function=FunctionDefinition(name='getCurrentWeather', parameters={'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The city and state e.g. San Francisco, CA'}, 'unit': {'type': 'string', 'enum': ['c', 'f']}}, 'required': ['location']}, description='Get the weather in location'), type='function'),\n",
       "  ToolAssistantToolsFunction(function=FunctionDefinition(name='getNickname', parameters={'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The city and state e.g. San Francisco, CA'}}, 'required': ['location']}, description='Get the nickname of a city'), type='function')]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_functions = {\n",
    "    \"getCurrentWeather\": getCurrentWeather,\n",
    "    \"getNickname\": getNickname\n",
    "} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thread_fzNe9S3rWyE6VCFpT8kclKXJ'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread.id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[39m# Loop until the run completes or requires action\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m----> 5\u001b[0m     runStatus \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mbeta\u001b[39m.\u001b[39mthreads\u001b[39m.\u001b[39mruns\u001b[39m.\u001b[39mretrieve(thread_id\u001b[39m=\u001b[39mthread\u001b[39m.\u001b[39mid,\n\u001b[1;32m      6\u001b[0m                                                   run_id\u001b[39m=\u001b[39mrun\u001b[39m.\u001b[39mid)\n\u001b[1;32m      7\u001b[0m     \u001b[39m# Add run steps retrieval here for debuging\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     run_steps \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mbeta\u001b[39m.\u001b[39mthreads\u001b[39m.\u001b[39mruns\u001b[39m.\u001b[39msteps\u001b[39m.\u001b[39mlist(thread_id\u001b[39m=\u001b[39mthread\u001b[39m.\u001b[39mid, run_id\u001b[39m=\u001b[39mrun\u001b[39m.\u001b[39mid)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "  # Loop until the run completes or requires action\n",
    "while True:\n",
    "    runStatus = client.beta.threads.runs.retrieve(thread_id=thread.id,\n",
    "                                                  run_id=run.id)\n",
    "    # Add run steps retrieval here for debuging\n",
    "    run_steps = client.beta.threads.runs.steps.list(thread_id=thread.id, run_id=run.id)\n",
    "    # show_json(\"Run Steps:\", run_steps)\n",
    "    print(runStatus.status ,'.....')\n",
    "\n",
    "    # This means run is making a function call   \n",
    "    if runStatus.status == \"requires_action\":\n",
    "        print(runStatus.status ,'.....')\n",
    "        print(\"Status: \", \"requires_action\")\n",
    "        show_json(\"submit_tool_outputs\", runStatus.required_action)\n",
    "        if runStatus.required_action.submit_tool_outputs and runStatus.required_action.submit_tool_outputs.tool_calls:\n",
    "            print(\"toolCalls present:\")\n",
    "            toolCalls = runStatus.required_action.submit_tool_outputs.tool_calls\n",
    "\n",
    "            tool_outputs = []\n",
    "            for toolcall in toolCalls:\n",
    "                function_name = toolcall.function.name\n",
    "                function_args = json.loads(toolcall.function.arguments)\n",
    "                \n",
    "                if function_name in available_functions:\n",
    "                    \n",
    "                    \n",
    "                    function_to_call = available_functions[function_name]\n",
    "                    print(function_to_call,function_to_call.__name__==\"getCurrentWeather\",\"================================================================\")\n",
    "                  \n",
    "                    if function_to_call.__name__ == \"getCurrentWeather\":\n",
    "                        \n",
    "                        response = function_to_call(\n",
    "                        location=function_args.get(\"location\"),\n",
    "                        unit=function_args.get(\"unit\")\n",
    "                        )\n",
    "                        \n",
    "                        \n",
    "                        tool_outputs.append({\n",
    "                                  \"tool_call_id\": toolcall.id,\n",
    "                                  \"output\": response\n",
    "                              })\n",
    "                    \n",
    "                    elif function_to_call.__name__ == \"getNickname\":\n",
    "                        response = function_to_call(\n",
    "                          location=function_args.get(\"location\")\n",
    "                          )\n",
    "                        tool_outputs.append({\n",
    "                          \"tool_call_id\": toolcall.id,\n",
    "                          \"output\": response,\n",
    "                              })\n",
    "            print(tool_outputs,\">>>>>\") \n",
    "            # Submit tool outputs and update the run\n",
    "            client.beta.threads.runs.submit_tool_outputs(\n",
    "                thread_id=thread.id,\n",
    "                run_id=run.id,\n",
    "                tool_outputs=tool_outputs)\n",
    "      \n",
    "    elif runStatus.status == \"completed\":\n",
    "        # List the messages to get the response\n",
    "        print(\"completed...........logic\")\n",
    "        messages: list[ThreadMessage] = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "        for message in messages.data:\n",
    "            role_label = \"User\" if message.role == \"user\" else \"Assistant\"\n",
    "            message_content = message.content[0].text.value\n",
    "            print(f\"{role_label}: {message_content}\\n\")\n",
    "        break  # Exit the loop after processing the completed run\n",
    "\n",
    "    elif run.status == \"failed\":\n",
    "      print(\"Run failed.\")\n",
    "      break\n",
    "\n",
    "    elif run.status in [\"in_progress\", \"queued\"]:\n",
    "      print(f\"Run is {run.status}. Waiting...\")\n",
    "      time.sleep(5)  # Wait for 5 seconds before checking again\n",
    "\n",
    "    else:\n",
    "      print(f\"Unexpected status: {run.status}\")\n",
    "      break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
